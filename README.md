# Credit Risk Assessment System

![GitHub](https://img.shields.io/github/license/yourusername/credit-risk-assessment)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![Last Commit](https://img.shields.io/github/last-commit/yourusername/credit-risk-assessment)

A production-ready machine learning system for predicting loan default probabilities and managing credit risk.

## ğŸ” Overview

This repository contains an end-to-end machine learning pipeline for credit risk assessment. I built this project to tackle the challenge of accurately predicting loan defaults while maintaining model explainability for regulatory compliance. The system combines traditional credit scoring techniques with modern ML approaches and is designed for real-world deployment in financial institutions.

## âœ¨ Key Features

- **End-to-end ML Pipeline**: From data ingestion to model deployment
- **Model Flexibility**: Multiple algorithms with ensemble capabilities
- **Comprehensive Feature Engineering**: Domain-specific credit risk features
- **API for Real-time Predictions**: Fast, scalable inference
- **Monitoring Dashboard**: Track model performance over time
- **Automated Drift Detection**: Ensure model reliability
- **Model Explainability**: SHAP values and feature importance

## ğŸ› ï¸ Tech Stack

- **Core**: Python 3.8+, pandas, numpy
- **Machine Learning**: scikit-learn, XGBoost, LightGBM
- **API**: FastAPI
- **Monitoring**: Dash, plotly
- **Testing**: pytest
- **Visualization**: matplotlib, seaborn

## âš™ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/credit-risk-assessment.git
cd credit-risk-assessment
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Create your configuration file by copying the template:
```bash
cp config/config.sample.yaml config/config.yaml
```

5. Edit the configuration to match your environment and data sources.

## ğŸš€ Usage

### Run the Full Pipeline

The quickest way to see everything in action is to run the complete workflow:

```bash
python main.py full-workflow
```

This command will:
1. Process training and test data (or generate synthetic data if none exists)
2. Engineer features
3. Train a credit risk model (default: gradient boosting)
4. Evaluate model performance
5. Generate visualization reports
6. Save the model for inference

### Individual Components

You can also run individual components of the pipeline:

```bash
# Process data only
python main.py process-data

# Train model
python main.py train

# Evaluate model
python main.py evaluate

# Start API server
python main.py api

# Start monitoring dashboard
python main.py monitor

# Run drift detection
python main.py detect-drift --current-data path/to/new_data.csv
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ processed_test.csv
â”‚   â”‚   â””â”€â”€ processed_train.csv
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ logs/
â”œâ”€â”€ models/
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ dashboard.py
â”‚   â””â”€â”€ drift_detection.py
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ model_performance/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ acquisition.py
â”‚   â”‚   â”œâ”€â”€ features.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”‚   â”œâ”€â”€ optimize.py
â”‚   â”‚   â”œâ”€â”€ predict.py
â”‚   â”‚   â””â”€â”€ train.py
â”‚   â””â”€â”€ visualization/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ eda.py
â”‚       â””â”€â”€ model_analysis.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ main.py
â””â”€â”€ README.md
```

## âš™ï¸ Configuration

The system uses two main configuration files:

### `config.yaml`

Contains general settings, paths, and data configurations:

```yaml
project:
  name: credit_risk_assessment
  version: 1.0.0

paths:
  raw_data: data/raw/
  processed_data: data/processed/
  models: models/
  reports: reports/

data:
  train_file: credit_data_train.csv
  test_file: credit_data_test.csv
  target: default_flag
  random_state: 42
  test_size: 0.3
  
features:
  categorical:
    - employment_status
    - housing_status
    - product_type
    - purpose
  numerical:
    - loan_amount
    - interest_rate
    - income
    - debt_to_income_ratio
    - credit_score
```

### `model_config.yaml`

Contains model-specific hyperparameters:

```yaml
gradient_boosting:
  n_estimators: 200
  learning_rate: 0.05
  max_depth: 4
  subsample: 0.8
  
logistic_regression:
  C: 0.1
  class_weight: balanced
  max_iter: 1000
```

## ğŸŒ API Reference

After starting the API server with `python main.py api`, you can access:

- API documentation: http://localhost:8000/docs
- OpenAPI spec: http://localhost:8000/openapi.json

### Example API Request

```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "customer_id": "CUST123",
    "loan_amount": 25000,
    "interest_rate": 0.042,
    "term": 36,
    "income": 85000,
    "debt_to_income_ratio": 0.32,
    "employment_status": "Employed",
    "housing_status": "Mortgage",
    "credit_score": 720,
    "purpose": "Debt Consolidation"
  }'
```

## ğŸ’» Local Development

For development, you can use the synthetic data generator built into the system:

```bash
# Generate synthetic data for development
python -c "from src.data.acquisition import create_dummy_data; create_dummy_data(10000).to_csv('data/raw/synthetic_credit_data.csv', index=False)"
```

Then run the pipeline using this data by updating your config.yaml.

## ğŸ“Š Monitoring Dashboard

The monitoring dashboard provides real-time insights into model performance. Start it with:

```bash
python main.py monitor
```

Visit http://localhost:8050 to access:
- Performance metrics over time
- Population stability index
- Risk tier distribution
- Feature drift detection
- Detailed reports

## ğŸ¤ Contributing

Contributions are welcome! To contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

Make sure to run tests before submitting:

```bash
pytest tests/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Notes

- The system automatically generates synthetic data if no real data is provided
- For production use, replace the synthetic data with real credit history data
- The model is designed to be explainable to comply with regulatory requirements
- Performance metrics in the reports directory help track model quality over time

---

Made with â¤ï¸ by Ajit
